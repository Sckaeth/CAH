{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-tuning\n",
    "In the initial phases of the training process, we first fine-tune the model based on the data. For the purpose of a preliminary analysis we use a BERT-base uncased model.\n",
    "\n",
    "Several considerations are made:\n",
    "1. We train a regression model to score each prompt-punchline combination. This allows for a ranking system of some sorts further down the line.\n",
    "2. To achieve this, we must replace each instance of \"_____\" with the chosen joke for that combination.\n",
    "3. We tokenize each combination and use it to fine-tune the regression model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports libraries relevant to the fine-tuning process.\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loads the data into a dataset, with a 80:20 training/test split.\n",
    "dataset = load_dataset(\"csv\", data_files=\"data/proc_cah_data.csv\", split=\"train\")\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loads the model and tokenizer for sequence classification.\n",
    "# We set the number of labels to 1 for a regression model.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1957088 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8039212c7ef447babdb4d6b382f92fcd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/489272 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fd1790734b143a9878052e7809c53bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
      "        num_rows: 1957088\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
      "        num_rows: 489272\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Pre-processes the dataset to match the fine-tuning process.\n",
    "def preprocess_function(examples):\n",
    "    # Initialises lists to allow for a combination of prompts/punchlines.\n",
    "    prompts = examples['black_card_text']\n",
    "    punchlines = examples['white_card_text']\n",
    "    combined = []\n",
    "\n",
    "    # Loops through the punchlines, combining them with their respective prompts. If no instance of \"_____\" is found, the punchline is added to the end.\n",
    "    for index, punchline in enumerate(punchlines):\n",
    "        if prompts[index].count('_____') == 0:\n",
    "            combined.append(f\"{prompts[index]} {punchline}\")\n",
    "        else:\n",
    "            combined.append(prompts[index].replace(\"_____\", punchline))\n",
    "\n",
    "    # Tokenizes the jokes formed through these combinations.\n",
    "    tokenized_examples = tokenizer(combined, max_length=512, padding=\"max_length\", truncation=True)\n",
    "    tokenized_examples['label'] = examples['won']\n",
    "    return tokenized_examples\n",
    "\n",
    "\n",
    "original_columns = dataset[\"train\"].column_names\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, num_proc=1, remove_columns=original_columns)\n",
    "print(tokenized_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sets the evaluation metric as mse.\n",
    "metric = evaluate.load(\"mse\")\n",
    "\n",
    "# Computes the metrics the evaluation phases.\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels, squared=False)\n",
    "\n",
    "# Trains the model and evaluates it.\n",
    "training_args = TrainingArguments(output_dir=\"Iterations/BERT/AT-3\", evaluation_strategy=\"epoch\", save_total_limit=2)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# trainer.train(resume_from_checkpoint=True)\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
